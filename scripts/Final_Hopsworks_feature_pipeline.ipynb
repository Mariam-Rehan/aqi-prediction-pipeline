{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting data from OpenMeteo, OpenWeather"
      ],
      "metadata": {
        "id": "W35LuXm7Al5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests-cache retry_requests openmeteo-requests\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "40LdlZpUDISu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5240bf49-d9ec-4638-fb97-6096920c098a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests-cache\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting retry_requests\n",
            "  Downloading retry_requests-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting openmeteo-requests\n",
            "  Downloading openmeteo_requests-1.3.0-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.11/dist-packages (from requests-cache) (24.3.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache)\n",
            "  Downloading cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-cache) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.11/dist-packages (from requests-cache) (2.32.3)\n",
            "Collecting url-normalize>=1.4 (from requests-cache)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.11/dist-packages (from requests-cache) (2.3.0)\n",
            "Collecting openmeteo-sdk>=1.4.0 (from openmeteo-requests)\n",
            "  Downloading openmeteo_sdk-1.18.6-py3-none-any.whl.metadata (935 bytes)\n",
            "Collecting flatbuffers==24.3.25 (from openmeteo-sdk>=1.4.0->openmeteo-requests)\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->requests-cache) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->requests-cache) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->requests-cache) (2024.12.14)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from url-normalize>=1.4->requests-cache) (1.17.0)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retry_requests-2.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading openmeteo_requests-1.3.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading cattrs-24.1.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmeteo_sdk-1.18.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: flatbuffers, url-normalize, openmeteo-sdk, cattrs, retry_requests, requests-cache, openmeteo-requests\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.12.23\n",
            "    Uninstalling flatbuffers-24.12.23:\n",
            "      Successfully uninstalled flatbuffers-24.12.23\n",
            "Successfully installed cattrs-24.1.2 flatbuffers-24.3.25 openmeteo-requests-1.3.0 openmeteo-sdk-1.18.6 requests-cache-1.2.1 retry_requests-2.0.0 url-normalize-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U 'hopsworks[python]' --quiet"
      ],
      "metadata": {
        "id": "j1e8Nw1Qx4ye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263d7676-6537-4707-cc96-eef10653b69f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.6/258.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.5/640.5 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for avro (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for twofish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta, datetime\n",
        "import requests\n",
        "import openmeteo_requests\n",
        "import requests_cache\n",
        "import pandas as pd\n",
        "from retry_requests import retry\n",
        "import hopsworks\n",
        "\n",
        "def feature_pipeline():\n",
        "\n",
        "    def fetch_aqi_data():\n",
        "      today = datetime.utcnow()\n",
        "      two_years_ago = today - timedelta(days=2*365)\n",
        "      current_unix_time = int(today.timestamp())\n",
        "\n",
        "      unix_start = int(two_years_ago.timestamp())  # Convert to UNIX timestamp\n",
        "\n",
        "      url = f\"http://api.openweathermap.org/data/2.5/air_pollution/history?lat=24.8546842&lon=67.0207055&start={unix_start}&end={current_unix_time}&appid=91c226421864cfa90475fb99cdad2ffe\"\n",
        "      response = requests.get(url)\n",
        "      raw = response.json()\n",
        "\n",
        "      aqi_df = pd.json_normalize(raw[\"list\"])\n",
        "\n",
        "      aqi_df['dt'] = pd.to_datetime(aqi_df['dt'], unit='s')\n",
        "      aqi_df.set_index('dt', inplace=True)\n",
        "      aqi_df.index = aqi_df.index.tz_localize(None)\n",
        "      return pd.DataFrame(aqi_df)\n",
        "\n",
        "    def fetch_weather_data():\n",
        "          # Setup the Open-Meteo API client with cache and retry on error\n",
        "          cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
        "          retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
        "          openmeteo = openmeteo_requests.Client(session = retry_session)\n",
        "\n",
        "          start_date = datetime.utcnow() - timedelta(days=2*365)\n",
        "          end_date = datetime.utcnow() - timedelta(days=1)\n",
        "\n",
        "          # Make sure all required weather variables are listed here\n",
        "          # The order of variables in hourly or daily is important to assign them correctly below\n",
        "          url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
        "          params = {\n",
        "            \"latitude\": 24.8546842,\n",
        "            \"longitude\": 67.0207055,\n",
        "            \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"rain\", \"pressure_msl\", \"surface_pressure\", \"wind_speed_10m\", \"wind_direction_10m\", \"wind_gusts_10m\"],\n",
        "            \"start_date\": start_date.strftime(\"%Y-%m-%d\"),\n",
        "            \"end_date\": end_date.strftime(\"%Y-%m-%d\")\n",
        "          }\n",
        "          responses = openmeteo.weather_api(url, params=params)\n",
        "\n",
        "          # Process first location. Add a for-loop for multiple locations or weather models\n",
        "          response = responses[0]\n",
        "          print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
        "          print(f\"Elevation {response.Elevation()} m asl\")\n",
        "          print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
        "          print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
        "\n",
        "          # Process hourly data. The order of variables needs to be the same as requested.\n",
        "          hourly = response.Hourly()\n",
        "          hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
        "          hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
        "          hourly_precipitation = hourly.Variables(2).ValuesAsNumpy()\n",
        "          hourly_rain = hourly.Variables(3).ValuesAsNumpy()\n",
        "          hourly_pressure_msl = hourly.Variables(4).ValuesAsNumpy()\n",
        "          hourly_surface_pressure = hourly.Variables(5).ValuesAsNumpy()\n",
        "          hourly_wind_speed_10m = hourly.Variables(6).ValuesAsNumpy()\n",
        "          hourly_wind_direction_10m = hourly.Variables(7).ValuesAsNumpy()\n",
        "          hourly_wind_gusts_10m = hourly.Variables(8).ValuesAsNumpy()\n",
        "\n",
        "          hourly_data = {\"date\": pd.date_range(\n",
        "            start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
        "            end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
        "            freq = pd.Timedelta(seconds = hourly.Interval()),\n",
        "            inclusive = \"left\"\n",
        "          )}\n",
        "\n",
        "          hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
        "          hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
        "          hourly_data[\"precipitation\"] = hourly_precipitation\n",
        "          hourly_data[\"rain\"] = hourly_rain\n",
        "          hourly_data[\"pressure_msl\"] = hourly_pressure_msl\n",
        "          hourly_data[\"surface_pressure\"] = hourly_surface_pressure\n",
        "          hourly_data[\"wind_speed_10m\"] = hourly_wind_speed_10m\n",
        "          hourly_data[\"wind_direction_10m\"] = hourly_wind_direction_10m\n",
        "          hourly_data[\"wind_gusts_10m\"] = hourly_wind_gusts_10m\n",
        "\n",
        "          weather_df = pd.DataFrame(data = hourly_data)\n",
        "          weather_df['date'] = pd.to_datetime(weather_df[\"date\"]).dt.tz_localize(None)\n",
        "\n",
        "          return pd.DataFrame(weather_df)\n",
        "\n",
        "    def fetch_remaining_weather_data():\n",
        "            # Setup the Open-Meteo API client with cache and retry on error\n",
        "          cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
        "          retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
        "          openmeteo = openmeteo_requests.Client(session = retry_session)\n",
        "\n",
        "          start_date = datetime.utcnow() - timedelta(days=6)\n",
        "          end_date = datetime.utcnow() - timedelta(days=1)\n",
        "\n",
        "          # Make sure all required weather variables are listed here\n",
        "          # The order of variables in hourly or daily is important to assign them correctly below\n",
        "          url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "          params = {\n",
        "            \"latitude\": 24.8546842,\n",
        "            \"longitude\": 67.0207055,\n",
        "            \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"rain\", \"pressure_msl\", \"surface_pressure\", \"wind_speed_10m\", \"wind_direction_10m\", \"wind_gusts_10m\"],\n",
        "            \"start_date\": start_date.strftime(\"%Y-%m-%d\"),\n",
        "            \"end_date\": end_date.strftime(\"%Y-%m-%d\")\n",
        "          }\n",
        "          responses = openmeteo.weather_api(url, params=params)\n",
        "\n",
        "          # Process first location. Add a for-loop for multiple locations or weather models\n",
        "          response = responses[0]\n",
        "          print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
        "          print(f\"Elevation {response.Elevation()} m asl\")\n",
        "          print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
        "          print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
        "\n",
        "          # Process hourly data. The order of variables needs to be the same as requested.\n",
        "          hourly = response.Hourly()\n",
        "          hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
        "          hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
        "          hourly_precipitation = hourly.Variables(2).ValuesAsNumpy()\n",
        "          hourly_rain = hourly.Variables(3).ValuesAsNumpy()\n",
        "          hourly_pressure_msl = hourly.Variables(4).ValuesAsNumpy()\n",
        "          hourly_surface_pressure = hourly.Variables(5).ValuesAsNumpy()\n",
        "          hourly_wind_speed_10m = hourly.Variables(6).ValuesAsNumpy()\n",
        "          hourly_wind_direction_10m = hourly.Variables(7).ValuesAsNumpy()\n",
        "          hourly_wind_gusts_10m = hourly.Variables(8).ValuesAsNumpy()\n",
        "\n",
        "          hourly_data = {\"date\": pd.date_range(\n",
        "            start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
        "            end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
        "            freq = pd.Timedelta(seconds = hourly.Interval()),\n",
        "            inclusive = \"left\"\n",
        "          )}\n",
        "\n",
        "          hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
        "          hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
        "          hourly_data[\"precipitation\"] = hourly_precipitation\n",
        "          hourly_data[\"rain\"] = hourly_rain\n",
        "          hourly_data[\"pressure_msl\"] = hourly_pressure_msl\n",
        "          hourly_data[\"surface_pressure\"] = hourly_surface_pressure\n",
        "          hourly_data[\"wind_speed_10m\"] = hourly_wind_speed_10m\n",
        "          hourly_data[\"wind_direction_10m\"] = hourly_wind_direction_10m\n",
        "          hourly_data[\"wind_gusts_10m\"] = hourly_wind_gusts_10m\n",
        "          remaining_df = pd.DataFrame(data = hourly_data)\n",
        "          remaining_df['date'] = pd.to_datetime(remaining_df[\"date\"]).dt.tz_localize(None)\n",
        "\n",
        "          return pd.DataFrame(remaining_df)\n",
        "\n",
        "    def preprocess_data(aqi_df, weather_df, remaining_df):\n",
        "          print(\"Preprocessing Data...\")\n",
        "          print(f\"AQI DataFrame Shape: {aqi_df.shape}\")\n",
        "          print(f\"Weather DataFrame Shape: {weather_df.shape}\")\n",
        "          print(f\"Remaining Weather DataFrame Shape: {remaining_df.shape}\")\n",
        "\n",
        "          # Concatenate weather data\n",
        "          merged_weather_df = pd.concat([weather_df, remaining_df], axis=0)\n",
        "          print(f\"Merged Weather DataFrame Shape: {merged_weather_df.shape}\")\n",
        "\n",
        "          # Perform the merge using \"dt\" and \"date\"\n",
        "          final_df = pd.merge(aqi_df, merged_weather_df, left_on=\"dt\", right_on=\"date\", how=\"inner\")\n",
        "          print(f\"Final Merged DataFrame Shape: {final_df.shape}\")\n",
        "\n",
        "          # Check NaN counts in the date column\n",
        "          print(f\"Number of NaNs in 'date': {final_df['date'].isna().sum()}\")\n",
        "\n",
        "          final_df.columns = final_df.columns.str.replace(r\"\\.\", \"_\", regex=True)\n",
        "          final_df.columns = final_df.columns.str.replace(r\"[^a-zA-Z0-9_]\", \"\", regex=True)\n",
        "          final_df.columns = final_df.columns.str.lower()\n",
        "\n",
        "          final_df['date'] = pd.to_datetime(final_df['date'])\n",
        "          final_df['day_of_week'] = final_df['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
        "          final_df['month'] = final_df['date'].dt.month\n",
        "          final_df['day_of_year'] = final_df['date'].dt.dayofyear\n",
        "          final_df['week_of_year'] = final_df['date'].dt.isocalendar().week\n",
        "          final_df['is_weekend'] = final_df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "          final_df['hour'] = final_df['date'].dt.hour\n",
        "\n",
        "          for lag in range(1, 4):  # Create 3 lags\n",
        "              final_df[f'aqi_lag_{lag}'] = final_df['main_aqi'].shift(lag)\n",
        "              final_df[f'temp_lag_{lag}'] = final_df['temperature_2m'].shift(lag)\n",
        "\n",
        "          final_df['aqi_lag_1'].bfill(inplace = True)\n",
        "          final_df['temp_lag_1'].bfill(inplace = True)\n",
        "          final_df['aqi_lag_2'].bfill(inplace = True)\n",
        "          final_df['temp_lag_2'].bfill(inplace = True)\n",
        "          final_df['aqi_lag_3'].bfill(inplace = True)\n",
        "          final_df['temp_lag_3'].bfill(inplace = True)\n",
        "\n",
        "          final_df.drop(columns = ['components_co', 'components_no', 'components_no2','components_o3', 'components_so2', 'components_pm2_5','components_pm10', 'components_nh3'], axis = 1, inplace = True)\n",
        "\n",
        "          # Fixing duplicate issues while prioritizing rows with fewer NaNs\n",
        "          df_cleaned = (\n",
        "              final_df.sort_values(\"date\", kind=\"mergesort\")\n",
        "              .assign(missing_count=final_df.isna().sum(axis=1))\n",
        "              .sort_values(by=[\"date\", \"missing_count\"])\n",
        "              .drop_duplicates(subset=\"date\", keep=\"first\")\n",
        "              .drop(columns=[\"missing_count\"])\n",
        "          )\n",
        "\n",
        "          df_cleaned.reset_index(drop=True, inplace=True)\n",
        "          print(f\"Cleaned DataFrame Shape: {df_cleaned.shape}\")\n",
        "          df_cleaned.dropna(inplace = True)\n",
        "          df_cleaned[\"index\"] = df_cleaned.index\n",
        "          return df_cleaned\n",
        "\n",
        "    aqi_df = fetch_aqi_data()\n",
        "    weather_df = fetch_weather_data()\n",
        "    remaining_df = fetch_remaining_weather_data()\n",
        "    final_df = preprocess_data(aqi_df, weather_df, remaining_df)\n",
        "    return final_df\n",
        "\n",
        "#Insert into Feature Store on Hopsworks\n",
        "project = hopsworks.login(api_key_value = \"HOPSWORKS_API_KEY\")\n",
        "fs = project.get_feature_store()\n",
        "\n",
        "air_quality_fg = fs.get_or_create_feature_group(\n",
        "    name=\"aqi_weather_features\",\n",
        "    version=2,\n",
        ")\n",
        "\n",
        "df = feature_pipeline()\n",
        "air_quality_fg.insert(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE646EVagWJL",
        "outputId": "89bff5e9-c3b3-459a-a385-a696ffcbcd5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection closed.\n",
            "\n",
            "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1209521\n",
            "Coordinates 24.850614547729492°N 66.99248504638672°E\n",
            "Elevation 8.0 m asl\n",
            "Timezone None None\n",
            "Timezone difference to GMT+0 0 s\n",
            "Coordinates 24.875°N 67.0°E\n",
            "Elevation 8.0 m asl\n",
            "Timezone None None\n",
            "Timezone difference to GMT+0 0 s\n",
            "Preprocessing Data...\n",
            "AQI DataFrame Shape: (17232, 9)\n",
            "Weather DataFrame Shape: (17520, 10)\n",
            "Remaining Weather DataFrame Shape: (144, 10)\n",
            "Merged Weather DataFrame Shape: (17664, 10)\n",
            "Final Merged DataFrame Shape: (17371, 19)\n",
            "Number of NaNs in 'date': 0\n",
            "Cleaned DataFrame Shape: (17227, 23)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Uploading Dataframe: 100.00% |██████████| Rows 17226/17226 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching job: aqi_weather_features_2_offline_fg_materialization\n",
            "Job started successfully, you can follow the progress at \n",
            "https://c.app.hopsworks.ai:443/p/1209521/jobs/named/aqi_weather_features_2_offline_fg_materialization/executions\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Job('aqi_weather_features_2_offline_fg_materialization', 'SPARK'), None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}
